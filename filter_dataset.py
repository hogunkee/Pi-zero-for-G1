#!/usr/bin/env python3
"""
LeRobot ë°ì´í„°ì…‹ì—ì„œ state modalityë¥¼ í•„í„°ë§í•˜ê³  
parquet, modality.json, norm_stats.jsonì„ ìˆ˜ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import shutil
from pathlib import Path
import pandas as pd
import numpy as np
from tqdm import tqdm


def filter_observation_state(state_value):
    """observation.stateì—ì„œ ì• 15ê°œ dof ì œê±° (index 15ë¶€í„°ë§Œ ìœ ì§€)"""
    if isinstance(state_value, (list, np.ndarray)):
        return state_value[15:]
    return state_value


def filter_parquet_files(dataset_path):
    """ë°ì´í„°ì…‹ ë‚´ ëª¨ë“  parquet íŒŒì¼ì˜ observation.state í•„í„°ë§"""
    dataset_path = Path(dataset_path)
    parquet_files = list(dataset_path.rglob("*.parquet"))
    
    print(f"\nğŸ“¦ Parquet íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
    print(f"  ë°œê²¬ëœ íŒŒì¼: {len(parquet_files)}ê°œ")
    
    for parquet_file in tqdm(parquet_files, desc="Filtering parquet files"):
        try:
            df = pd.read_parquet(parquet_file)
            if "observation.state" in df.columns:
                df["observation.state"] = df["observation.state"].apply(filter_observation_state)
                df.to_parquet(parquet_file)
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ ({parquet_file}): {e}")
    
    print(f"  âœ“ ëª¨ë“  parquet íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")


def filter_and_copy_dataset(source_dataset_path, dest_dataset_path):
    """ë°ì´í„°ì…‹ì„ ë³µì œí•˜ê³  stateë¥¼ í•„í„°ë§í•˜ë©° ëª¨ë“  íŒŒì¼ì„ ìˆ˜ì •"""
    
    source_path = Path(source_dataset_path)
    dest_path = Path(dest_dataset_path)
    
    print("=" * 70)
    print("LeRobot ë°ì´í„°ì…‹ í•„í„°ë§ ì‹œì‘")
    print("=" * 70)
    
    if dest_path.exists():
        print(f"\nâš ï¸  '{dest_dataset_path}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì‚­ì œí•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤.")
        shutil.rmtree(dest_path)
    
    print(f"\nğŸ“‚ ë°ì´í„°ì…‹ ë³µì œ ì¤‘...")
    shutil.copytree(source_path, dest_path)
    print(f"âœ“ ë°ì´í„°ì…‹ ë³µì œ ì™„ë£Œ")
    
    # Parquet íŒŒì¼ë“¤ í•„í„°ë§
    filter_parquet_files(dest_path)
    
    # modality.json ìˆ˜ì •
    modality_path = dest_path / "meta" /  "modality.json"
    print(f"\nğŸ“ modality.json ìˆ˜ì • ì¤‘...")
    
    with open(modality_path, 'r') as f:
        modality = json.load(f)
    
    new_state = {
        "left_arm": {"start": 0, "end": 7},
        "right_arm": {"start": 7, "end": 14},
        "left_hand": {"start": 14, "end": 21},
        "right_hand": {"start": 21, "end": 28}
    }
    modality["state"] = new_state
    
    with open(modality_path, 'w') as f:
        json.dump(modality, f, indent=2)
    
    print(f"  âœ“ modality.json ìˆ˜ì • ì™„ë£Œ")
    
    # norm_stats.json ìˆ˜ì •
    norm_stats_path = dest_path / "g1" / "norm_stats.json"
    print(f"\nğŸ“Š norm_stats.json ìˆ˜ì • ì¤‘...")
    
    if norm_stats_path.exists():
        with open(norm_stats_path, 'r') as f:
            norm_stats = json.load(f)
        
        for stat_key in ["mean", "std", "q01", "q99"]:
            norm_stats["norm_stats"]["state"][stat_key] = \
                norm_stats["norm_stats"]["state"][stat_key][15:]
        
        with open(norm_stats_path, 'w') as f:
            json.dump(norm_stats, f, indent=2)
        
        print(f"  âœ“ norm_stats.json ìˆ˜ì • ì™„ë£Œ")
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!\n")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="LeRobot ë°ì´í„°ì…‹ í•„í„°ë§")
    parser.add_argument("source", help="ì›ë³¸ ë°ì´í„°ì…‹ ê²½ë¡œ")
    parser.add_argument("dest", help="ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ê²½ë¡œ")
    
    args = parser.parse_args()
    filter_and_copy_dataset(args.source, args.dest)
